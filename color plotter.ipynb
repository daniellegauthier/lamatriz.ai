{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bec0767-04f4-411d-9965-f014bb319c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.local/lib/python3.13/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: sentence-transformers in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (5.1.2)\n",
      "Requirement already satisfied: gradio in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (6.0.1)\n",
      "Requirement already satisfied: spacy in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (3.8.11)\n",
      "Requirement already satisfied: nltk in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (4.7.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in ./.local/lib/python3.13/site-packages (from gradio) (0.122.0)\n",
      "Requirement already satisfied: ffmpy in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.0.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in ./.local/lib/python3.13/site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.12.4)\n",
      "Requirement already satisfied: pydub in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in ./.local/lib/python3.13/site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in ./.local/lib/python3.13/site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.local/lib/python3.13/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in ./.local/lib/python3.13/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.17.0)\n",
      "Requirement already satisfied: joblib in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Volumes/mac/opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy torch transformers sentence-transformers gradio spacy nltk pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fc26bef-fe87-4af0-b683-689a527b40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7887\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, re\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import nltk, spacy, torch, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import gradio as gr\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# -------------------- setup --------------------\n",
    "def ensure_spacy():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except Exception:\n",
    "        import spacy.cli\n",
    "        spacy.cli.download(\"en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ensure_nltk():\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt\")\n",
    "    except LookupError:\n",
    "        nltk.download(\"punkt\")\n",
    "\n",
    "ensure_nltk()\n",
    "nlp = ensure_spacy()\n",
    "\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "bert_sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "emotion_model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "emotion_tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name)\n",
    "\n",
    "# -------------------- constants --------------------\n",
    "CSV_PATH_PLUS  = \"la matrice plus.csv\"   # pathways + colors + template words\n",
    "CSV_PATH_COLOR = \"la matrice.csv\"        # color lexicon\n",
    "\n",
    "SEQUENCE_ALIASES = {\n",
    "    \"Direct\": \"direct\",\n",
    "    \"Feminine\": \"feminine\",\n",
    "    \"Knot\": \"knot\",\n",
    "    \"Masculine\": \"masc\",\n",
    "    \"Pain\": \"pain\",\n",
    "    \"Prayer\": \"prayer\",\n",
    "    \"Precise\": \"precise\",\n",
    "    \"Practical\": \"practical\",\n",
    "    \"Plot\": \"plot\",\n",
    "    \"Spiritual\": \"spiritual\",\n",
    "    \"Sad\": \"sad\",\n",
    "}\n",
    "\n",
    "SEQUENCE_IMAGE_FILES = {\n",
    "    \"direct\": \"direct pathway.png\",\n",
    "    \"feminine\": \"fem pathway.png\",\n",
    "    \"knot\": \"knot pathway.png\",\n",
    "    \"masc\": \"masc pathway.png\",\n",
    "    \"pain\": \"pain pathway.png\",\n",
    "    \"prayer\": \"prayer pathway.png\",\n",
    "    \"precise\": \"precise pathway.png\",\n",
    "    \"practical\": \"practical pathway.png\",\n",
    "    \"plot\": \"plot pathway.png\",\n",
    "    \"spiritual\": \"spiritual pathway.png\",\n",
    "    \"sad\": \"sad pathway.png\"\n",
    "}\n",
    "\n",
    "GNH_DOMAINS: Dict[str, str] = {\n",
    "    \"Mental Wellness\": \"mental health, emotional clarity, peace of mind\",\n",
    "    \"Social Wellness\": \"relationships, community, friendship, social harmony\",\n",
    "    \"Economic Wellness\": \"income, savings, financial stability, cost of living\",\n",
    "    \"Workplace Wellness\": \"career, work-life balance, promotion, productivity\",\n",
    "    \"Physical Wellness\": \"physical health, sleep, fitness, exercise\",\n",
    "    \"Environmental Wellness\": \"green space, nature, environmental care\",\n",
    "    \"Health\": \"healthcare, medical care, recovery, well-being\",\n",
    "    \"Education Value\": \"learning, education, school, knowledge, wisdom\",\n",
    "    \"Good Governance\": \"freedom, justice, fairness, democratic participation\",\n",
    "    \"Living Standards\": \"housing, wealth, basic needs, affordability\",\n",
    "    \"Cultural Diversity\": \"tradition, language, cultural expression, heritage\",\n",
    "    \"Political Wellness\": \"rights, law, free speech, civic participation\",\n",
    "    \"Ecological Diversity\": \"biodiversity, forest, ecosystem, wildlife\",\n",
    "}\n",
    "\n",
    "GNH_COLORS: Dict[str, str] = {\n",
    "    \"Economic Wellness\": \"#808080\",\n",
    "    \"Mental Wellness\": \"#FA005A\",\n",
    "    \"Workplace Wellness\": \"#ffd700\",\n",
    "    \"Physical Wellness\": \"#FAB478\",\n",
    "    \"Social Wellness\": \"#ffa500\",\n",
    "    \"Political Wellness\": \"#ffffff\",\n",
    "    \"Environmental Wellness\": \"#0000FF\",\n",
    "    \"Ecological Diversity\": \"#00FF00\",\n",
    "    \"Health\": \"#FF0000\",\n",
    "    \"Good Governance\": \"#000000\",\n",
    "    \"Education Value\": \"#8b4513\",\n",
    "    \"Living Standards\": \"#ffff00\",\n",
    "    \"Cultural Diversity\": \"#B432FF\",\n",
    "}\n",
    "\n",
    "WORD_MODES = [\"Receiver\", \"Transmitter\", \"English Words\", \"GNH Indicators\", \"Keys\", \"Sound\"]\n",
    "\n",
    "MODE_TO_LEX_KEY = {\n",
    "    \"receiver\": \"receiver\",\n",
    "    \"transmitter\": \"transmitter\",\n",
    "    \"english words\": \"english-words\",\n",
    "    \"gnh indicators\": \"gnh-indicator\",\n",
    "    \"keys\": \"key\",\n",
    "    \"sound\": \"sound\",\n",
    "}\n",
    "\n",
    "MAX_COLORS = 8\n",
    "\n",
    "# -------------------- loaders --------------------\n",
    "def _find_col(df: pd.DataFrame, candidates: List[str]) -> str | None:\n",
    "    names = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c.lower() in names: return names[c.lower()]\n",
    "    for want in candidates:\n",
    "        ww = want.replace(\" \", \"\").replace(\"-\", \"\")\n",
    "        for lc, orig in names.items():\n",
    "            if ww in lc.replace(\" \", \"\").replace(\"-\", \"\"):\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "def load_pathway_info(csv_path_plus: str):\n",
    "    df = pd.read_csv(csv_path_plus)\n",
    "    keys = set(SEQUENCE_ALIASES.values())\n",
    "    rows = df[df[\"color\"].astype(str).str.lower().isin(keys)].copy()\n",
    "\n",
    "    seq_to_colors: Dict[str, List[str]] = {}\n",
    "    seq_phrase: Dict[str, str] = {}\n",
    "\n",
    "    # colors live in 'r' (list), template = concat of the other fields\n",
    "    cols_for_phrase = [c for c in df.columns if c not in (\"color\", \"r\", \"g\", \"b\")]\n",
    "    for _, row in rows.iterrows():\n",
    "        key = str(row[\"color\"]).strip().lower()\n",
    "        color_list = str(row.get(\"r\", \"\") or \"\")\n",
    "        colors = [c.strip().lower() for c in re.split(r\"[,\\s]+\", color_list) if c.strip()]\n",
    "        seq_to_colors[key] = list(dict.fromkeys(colors))\n",
    "\n",
    "        vals = []\n",
    "        for c in cols_for_phrase:\n",
    "            v = row.get(c)\n",
    "            if pd.notna(v):\n",
    "                s = str(v).strip()\n",
    "                if s and s.lower() != \"nan\":\n",
    "                    vals.append(s)\n",
    "        phrase = \" \".join(\" \".join(vals).split())  # base template\n",
    "        seq_phrase[key] = phrase\n",
    "\n",
    "    return seq_to_colors, seq_phrase\n",
    "\n",
    "def _split_words(s: str) -> List[str]:\n",
    "    if not isinstance(s, str): return []\n",
    "    parts = re.split(r\"[,\\;/\\|\\s]+\", s.strip())\n",
    "    return [p for p in (w.strip().lower() for w in parts) if p]\n",
    "\n",
    "def load_color_lexicon(csv_path_color: str):\n",
    "    df = pd.read_csv(csv_path_color)\n",
    "    color_col = _find_col(df, [\"color\", \"colour\"])\n",
    "    r_col = _find_col(df, [\"receiver\"])\n",
    "    t_col  = _find_col(df, [\"transmitter\"])\n",
    "    en_col = _find_col(df, [\"english-words\"])\n",
    "    gnh_col  = _find_col(df, [\"gnh-indicator\"])\n",
    "    k_col  = _find_col(df, [\"key\"])\n",
    "    s_col  = _find_col(df, [\"sound\"])\n",
    "\n",
    "    lex: Dict[str, Dict[str, str]] = {}\n",
    "    for _, row in df.iterrows():\n",
    "        cname = str(row.get(color_col, \"\")).strip().lower()\n",
    "        if not cname: \n",
    "            continue\n",
    "        lex[cname] = {\n",
    "            \"receiver\": str(row.get(r_col, \"\") or \"\").strip(),\n",
    "            \"transmitter\": str(row.get(t_col, \"\") or \"\").strip(),\n",
    "            \"english-words\": str(row.get(en_col, \"\") or \"\").strip(),\n",
    "            \"gnh-indicator\": str(row.get(gnh_col, \"\") or \"\").strip(),\n",
    "            \"key\": str(row.get(k_col, \"\") or \"\").strip(),\n",
    "            \"sound\": str(row.get(s_col, \"\") or \"\").strip()\n",
    "        }\n",
    "    return lex\n",
    "\n",
    "\n",
    "SEQ_TO_COLORS, SEQ_PHRASE = load_pathway_info(CSV_PATH_PLUS)\n",
    "COLOR_LEX = load_color_lexicon(CSV_PATH_COLOR)\n",
    "\n",
    "def sequence_to_image_path(seq_key: str) -> str | None:\n",
    "    fname = SEQUENCE_IMAGE_FILES.get(seq_key)\n",
    "    return fname if (fname and os.path.exists(fname)) else None\n",
    "\n",
    "# -------------------- NLP helpers --------------------\n",
    "def encode_text(t: str):\n",
    "    return sbert_model.encode(t, convert_to_tensor=True)\n",
    "\n",
    "def classify_emotion(text: str) -> Tuple[str, float]:\n",
    "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=1).squeeze()\n",
    "    labels = emotion_model.config.id2label\n",
    "    idx = int(torch.argmax(probs).item())\n",
    "    return labels[idx], float(probs[idx].item())\n",
    "\n",
    "def score_sentiment(text: str) -> float:\n",
    "    out = bert_sentiment(text[:512])[0]\n",
    "    label, score = out[\"label\"], out[\"score\"]\n",
    "    scaled = 5 + 5 * score if label == \"POSITIVE\" else 1 + 4 * (1 - score)\n",
    "    return round(min(10, max(1, scaled)), 2)\n",
    "\n",
    "def score_accomplishment(text: str) -> float:\n",
    "    doc = nlp(text); score = 5.0\n",
    "    key_phrases = {\"finally\",\"told\",\"decided\",\"quit\",\"refused\",\"stood\",\"walked\",\"walked away\",\"returned\",\"return\"}\n",
    "    for token in doc:\n",
    "        if token.text.lower() in key_phrases: score += 1.5\n",
    "        if token.tag_ in {\"VBD\",\"VBN\"}:       score += 0.5\n",
    "    return round(min(10, max(1, score)), 2)\n",
    "\n",
    "def semantic_indicator_mapping(text: str, sentiment_score: float, sentiment_weight: float = 0.3) -> Dict[str, float]:\n",
    "    v = encode_text(text)\n",
    "    out: Dict[str, float] = {}\n",
    "    for dom, desc in GNH_DOMAINS.items():\n",
    "        sim = float(util.cos_sim(v, encode_text(desc)).item())\n",
    "        sim = max(0.0, min(1.0, sim))\n",
    "        blended = (1 - sentiment_weight) * sim + sentiment_weight * (sentiment_score / 10.0)\n",
    "        out[dom] = round(blended, 3)\n",
    "    return dict(sorted(out.items(), key=lambda kv: -kv[1]))\n",
    "\n",
    "def indicators_plot(indicators: Dict[str, float]):\n",
    "    labels = list(indicators.keys()); values = list(indicators.values())\n",
    "    colors = [GNH_COLORS.get(label, \"#cccccc\") for label in labels]\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    plt.barh(labels, values, color=colors)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"GNH Indicator Similarity\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# -------------------- prompt building (legible placeholders) --------------------\n",
    "def join_all_words(color: str) -> List[str]:\n",
    "    d = COLOR_LEX.get(color.lower(), {})\n",
    "    return list(dict.fromkeys(d.get(\"receiver\", []) + d.get(\"transmitter\", []) + d.get(\"english-words\", []) + d.get(\"gnh-indicator\", []) + d.get(\"key\", []) + d.get(\"sound\", [])))\n",
    "\n",
    "def nearest_gnh_domain_for_color(color: str) -> Tuple[str, float]:\n",
    "    words = \" \".join(join_all_words(color))\n",
    "    if not words:\n",
    "        return \"Mental Wellness\", 0.0\n",
    "    v = encode_text(words)\n",
    "    best, best_sim = None, -1.0\n",
    "    for dom, desc in GNH_DOMAINS.items():\n",
    "        sim = float(util.cos_sim(v, encode_text(desc)).item())\n",
    "        if sim > best_sim:\n",
    "            best, best_sim = dom, sim\n",
    "    return best or \"Mental Wellness\", best_sim\n",
    "\n",
    "def labels_for_mode(colors: List[str], mode: str) -> List[str]:\n",
    "    if mode.lower().startswith(\"gnh\"):\n",
    "        return [nearest_gnh_domain_for_color(c)[0] for c in colors]\n",
    "    return [c.capitalize() for c in colors]\n",
    "    \n",
    "def placeholder_for(color: str, mode: str) -> str:\n",
    "    \"\"\"\n",
    "    Placeholder directly from the CSV column corresponding to the word mode.\n",
    "    \"\"\"\n",
    "    if not color or not mode:\n",
    "        return \"\"\n",
    "    \n",
    "    color_lc = color.lower()\n",
    "    mode_key = MODE_TO_LEX_KEY.get(mode.lower())\n",
    "    if not mode_key:\n",
    "        return \"\"\n",
    "\n",
    "    lex_entry = COLOR_LEX.get(color_lc)\n",
    "    if not lex_entry:\n",
    "        return \"\"\n",
    "\n",
    "    placeholder_text = lex_entry.get(mode_key, \"\")\n",
    "    return placeholder_text\n",
    "\n",
    "\n",
    "def simple_color_legend(colors: List[str]) -> str:\n",
    "    if not colors:\n",
    "        return \"No prompts available for this pathway.\"\n",
    "    parts = []\n",
    "    for c in colors:\n",
    "        dot = f\"<span style='display:inline-block;width:10px;height:10px;border-radius:50%;background:{c};margin-right:8px;border:1px solid #999;vertical-align:middle'></span>\"\n",
    "        parts.append(f\"<div style='margin:4px 0'>{dot}<b>{c.capitalize()}</b></div>\")\n",
    "    return \"<div>\" + \"\".join(parts) + \"</div>\"\n",
    "\n",
    "def colors_for_sequence(seq_key: str) -> List[str]:\n",
    "    return SEQ_TO_COLORS.get(seq_key, [])\n",
    "\n",
    "def update_prompt_ui(seq_choice: str, word_mode: str, *current_values):\n",
    "    \"\"\"\n",
    "    Updates the color input boxes:\n",
    "      - Label = \"ColorName meaning\"\n",
    "      - Placeholder = CSV words for chosen word mode\n",
    "      - PRESERVES current values when just changing mode\n",
    "    \"\"\"\n",
    "    key = SEQUENCE_ALIASES.get(seq_choice)\n",
    "    colors = colors_for_sequence(key)\n",
    "    legend_html = simple_color_legend(colors)\n",
    "\n",
    "    updates = []\n",
    "    for i in range(MAX_COLORS):\n",
    "        if i < len(colors):\n",
    "            color_name = colors[i].capitalize()\n",
    "            ph = placeholder_for(colors[i], word_mode)\n",
    "            # Preserve existing value if available\n",
    "            current_val = current_values[i] if i < len(current_values) else \"\"\n",
    "            updates.append(gr.update(visible=True, label=f\"{color_name} meaning\", placeholder=ph, value=current_val))\n",
    "        else:\n",
    "            updates.append(gr.update(visible=False, value=\"\", label=f\"Input {i+1}\", placeholder=\"—\"))\n",
    "    return (legend_html, *updates)\n",
    "\n",
    "# -------------------- template replacement --------------------\n",
    "def render_phrase_template(base_phrase: str, colors: List[str], labels: List[str], inputs: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Replace occurrences of '<color>-pathway' (any spacing/hyphen variants) with the user's phrase for that color.\n",
    "    If user left it empty, keep the label (color name or mapped GNH indicator).\n",
    "    Finally, append a compact legend ' // Label: input'.\n",
    "    \"\"\"\n",
    "    text = base_phrase or \"\"\n",
    "    # build replacement map color -> replacement text\n",
    "    rep: Dict[str, str] = {}\n",
    "    for color, label, user in zip(colors, labels, inputs):\n",
    "        use = user.strip() if isinstance(user, str) and user.strip() else label\n",
    "        rep[color.lower()] = use\n",
    "\n",
    "    # replace each token case-insensitively\n",
    "    for color, replacement in rep.items():\n",
    "        # match 'brown-pathway', 'brown pathway', 'Brown- Pathway', etc.\n",
    "        pattern = re.compile(rf\"\\b{re.escape(color)}\\s*-\\s*pathway\\b\", re.IGNORECASE)\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    # if the template had no tokens, fall back to readable construction:\n",
    "    # \"use A to B the C of D as a new E\" is preserved, but we still append meanings\n",
    "    suffix_parts = []\n",
    "    for color, label, user in zip(colors, labels, inputs):\n",
    "        if isinstance(user, str) and user.strip():\n",
    "            suffix_parts.append(f\"{label}: {user.strip()}\")\n",
    "    if suffix_parts:\n",
    "        text = (text + \" // \" + \" // \".join(suffix_parts)).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# -------------------- main analysis --------------------\n",
    "def analyze(text: str, seq_choice: str, word_mode: str, *color_inputs):\n",
    "    key = SEQUENCE_ALIASES.get(seq_choice)\n",
    "    if key not in SEQ_PHRASE:\n",
    "        return (5.0, \"neutral (0.0)\", 5.0, \"Choose a valid pathway.\", \"{}\", None, None, f\"{seq_choice} (unavailable)\",\n",
    "                *update_prompt_ui(seq_choice, word_mode, *color_inputs))\n",
    "\n",
    "    colors = colors_for_sequence(key)\n",
    "    labels = labels_for_mode(colors, word_mode)\n",
    "    base_phrase = SEQ_PHRASE.get(key, \"\")\n",
    "\n",
    "    # updated phrase with template replacement\n",
    "    user_inputs = list(color_inputs)[:len(colors)]\n",
    "    updated_phrase = render_phrase_template(base_phrase, colors, labels, user_inputs)\n",
    "\n",
    "    # analysis on original + updated\n",
    "    combined_text = \" \".join([t for t in [text, updated_phrase] if t and t.strip()])\n",
    "    sentiment = score_sentiment(combined_text)\n",
    "    emotion, emo_conf = classify_emotion(combined_text)\n",
    "    accomplishment = score_accomplishment(combined_text)\n",
    "\n",
    "    indicators = semantic_indicator_mapping(combined_text, sentiment_score=sentiment)\n",
    "    fig = indicators_plot(indicators)\n",
    "    top5 = list(indicators.items())[:5]\n",
    "    top5_str = \"\\n\".join(f\"{k}: {v}\" for k, v in top5)\n",
    "\n",
    "    img_path = sequence_to_image_path(key)\n",
    "    meta = f\"{key} | colors: {', '.join(colors) if colors else '—'}\"\n",
    "    emo_str = f\"{emotion} ({emo_conf:.3f})\"\n",
    "\n",
    "    # keep prompt area synced - PRESERVE user inputs\n",
    "    prompt_updates = update_prompt_ui(seq_choice, word_mode, *color_inputs)\n",
    "\n",
    "    return (\n",
    "        sentiment, emo_str, accomplishment,\n",
    "        updated_phrase, top5_str, fig, img_path, meta,\n",
    "        *prompt_updates\n",
    "    )\n",
    "\n",
    "# -------------------- UI --------------------\n",
    "SEQ_CHOICES = list(SEQUENCE_ALIASES.keys())\n",
    "DEFAULT_SEQ = \"Knot\" if \"Knot\" in SEQ_CHOICES else SEQ_CHOICES[0]\n",
    "\n",
    "with gr.Blocks(title=\"RGB Root Matriz Color Plotter\") as demo:\n",
    "    gr.Markdown(\"## RGB Root Matriz Color Plotter\\n\"\n",
    "                \"Type a phrase. Choose a **Sequence**. \"\n",
    "                \"You'll get sentiment, emotion, accomplishment, GNH bars, and the pathway phrase + image from the dataset.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        inp = gr.Textbox(lines=4, label=\"Your situation / obstacle\", placeholder=\"Describe the situation...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        seq = gr.Dropdown(choices=SEQ_CHOICES, value=DEFAULT_SEQ, label=\"Pathway\")\n",
    "        word_mode = gr.Radio(choices=WORD_MODES, value=\"Receiver\", label=\"Word Mode\")\n",
    "\n",
    "    legend = gr.HTML()\n",
    "\n",
    "    color_boxes: List[gr.Textbox] = []\n",
    "    for i in range(MAX_COLORS):\n",
    "        color_boxes.append(\n",
    "            gr.Textbox(\n",
    "                visible=True,          # MUST be True initially\n",
    "                label=f\"Input {i+1}\",\n",
    "                placeholder=\"—\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    run = gr.Button(\"Generate Pathway Analysis\", variant=\"primary\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent = gr.Number(label=\"Sentiment (1–10)\")\n",
    "        emo  = gr.Text(label=\"Emotion\")\n",
    "        acc  = gr.Number(label=\"Accomplishment (1–10)\")\n",
    "\n",
    "    with gr.Row():\n",
    "        phrase_out = gr.Text(label=\"Updated Pathway Phrase (template with your meanings)\")\n",
    "        gnh_top    = gr.Text(label=\"Top GNH Indicators (Top 5)\")\n",
    "\n",
    "    gnh_plot = gr.Plot(label=\"GNH Similarity\")\n",
    "    img_out  = gr.Image(label=\"Pathway image\", type=\"filepath\")\n",
    "    meta_out = gr.Text(label=\"Chosen pathway / colors\")\n",
    "\n",
    "    def _update_ui(seq_choice, mode, *current_values):\n",
    "        return update_prompt_ui(seq_choice, mode, *current_values)\n",
    "\n",
    "    # KEY FIX: Pass current color_boxes values to preserve them when changing mode\n",
    "    seq.change(fn=_update_ui, inputs=[seq, word_mode, *color_boxes], outputs=[legend, *color_boxes])\n",
    "    word_mode.change(fn=_update_ui, inputs=[seq, word_mode, *color_boxes], outputs=[legend, *color_boxes])\n",
    "\n",
    "    run.click(\n",
    "        fn=analyze,\n",
    "        inputs=[inp, seq, word_mode, *color_boxes],\n",
    "        outputs=[sent, emo, acc, phrase_out, gnh_top, gnh_plot, img_out, meta_out, legend, *color_boxes],\n",
    "    )\n",
    "\n",
    "    demo.load(fn=_update_ui, inputs=[seq, word_mode, *color_boxes], outputs=[legend, *color_boxes])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue()\n",
    "    demo.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5ac1f-0f17-4e44-a973-d68a43322fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
